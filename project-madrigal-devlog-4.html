<!DOCTYPE html>
<html lang="en">
<meta name="viewport" content="width=device-width, initial-scale=0.5">
<head>
        <link rel="stylesheet" type="text/css" href="/css/style.css">
        <title>Montana Mott</title>
</head>
<body class="primary-dark">
  <div class="header-div"> 
    <h1 class="name"> <a style="color:white" href='project-madrigal.html'>> Project Madrigal </a> </h1>
  </div>
  <div class="left-aligned center-section">
    <h1 class="header-size light-font padded"> 
      It's Deferred Rendering time!
    </h1>
    <p class="small-size light-font padded"> 
    In my  <a href='project-madrigal-devlog-3.html'> most recent blogpost</a> for Project Madrigal, I mentioned that forward additive lighting in Unity for raymarched geometry was doomed to fail. Because of that and a few other reasons, I have made the switch to 
    using the Deferred Rendering Path of the Built-in Render Pipeline in Unity. This means that I adjusted my shader to write to the several g-buffer Render Targets in order to draw my geometry, instead of 
    doing the lighting calculations and returning a fragment color like I would in Forward rendering. Specifically, I write to the ARGB32 Diffuse Color/Occlusion buffer, the ARGB32 Specular Color/Roughness buffer, 
    the ARGB2101010 World Space Normal buffer, and finally the ARGB2101010 Emission + lighting buffer (and of course, as always, our good friend, the depth buffer). 

    <br/> <br/> 
    The great thing about deferred here is that once these buffers are written to appropriately, the lighting model can be whatever the user wants it to be! If I had gone the Forward rendering route, 
    I likely would have chosen a lighting model to build my project around, but now it is essentially made independent of the lighting model.
    <br/> <br/> 

    So I wrote <a href='https://github.com/montanamott/unity-raymarch-shader/blob/main/RaymarchGeo.shader'>my deferred shader </a> as specified above, but I noticed that... the lighting on my geometry wasn't quite right. Here is a picture of a scene I made for explanation purposes, where I have placed a point light just in front of some 
    raymarched geometry -- the point light is centered such that the geometry should be lit symmetrically. But... what's going on with that lower right corner? 


    <div class="padded content-embed">
      <img  width="640vh" height="376vh" src="images/single_point_light.PNG" alt="A scene in unity demonstrating incorrect lighting">
    </div>

    <p class="small-size light-font padded"> 
      I triple checked my raymarching code to make sure I was calculating my depths and normals the same as I was when they worked before. The relevant parts seemed correct, so I was stumped. My gut feeling, though, was that 
      the issue still had to do with normals, so I peeked at the g-buffer that contains normals (I almost used RenderDoc to look at this before realizing Unity can display g-buffers in the Frame Debugger! Useful). I put a raymarched cube on top of a regular Unity cube so I could check that the normals were the same and.... here was what the normal 
      buffer looked like: 

    </p>

      <div class="padded content-embed">
        <img  width="640vh" height="376vh" src="images/normals_debug_cube.PNG" alt="A view of a memory buffer containing normal vectors">
      </div>

      <p class="small-size light-font padded"> 
       There's a mismatch! My normals, on top, seem to be exactly (1, 0, 0) for example, whereas the ones Unity generated by default were... different. In hindsight, I should have noticed it right away, but I thought maybe 
       there was some sort of normals encoding going on for the buffer. It turns out, however, that the normals buffer in Unity is actually ARGB2101010_UNORM (emphasis on the UNORM). This is significant because my normals I was writing 
       had values ranging from -1 to 1, when they should have ranged from 0 to 1! Fixing this was simple, but this process of debugging helped me get more familiar with the graphics workflow in Unity, which I am grateful for. 
       Now our lighting looks like it should! </p>

       <div class="padded content-embed">
        <img  width="640vh" height="376vh" src="images/corrected_normals.PNG" alt="A scene in unity demonstrating correct lighting">
      </div>

      <p class="small-size light-font padded">
        And now I have the capability of drawing deferred raymarched geometry that casts and recieves shadows from rasterized and raymarched geometry and recieves light from multiple sources in real time! </p>
        
        <div class="padded content-embed">
          <img  width="640vh" height="376vh" src="images/additive_colors.PNG" alt="A scene in unity demonstrating correct lighting">
        </div>

        <p class="small-size light-font padded"> 
        Now it's time to 
        render some... nicer scenes with it!  I've wanted to do some fractal-based rendering for a while now, so I added support for drawing Menger Sponges into my project and added some pretty lighting, with a rasterized model to demonstrate 
        everything working together so far! To warn you though... I am not an artist. Ok I've warned you. I now present to you some Penguins that I modeled poorly in Blender clustered around light and warmth in their natural 
        habitat of a Menger Sponge! 


      </p>

      <div class="padded content-embed">
        <img  width="640vh" height="376vh" src="images/penguins_in_habitat.PNG">
      </div>


        <p class="small-size light-font padded"> 
       And there you have it! Next week I plan to do some work with physics to make these raymarched solids interactable. I will also continue graphics work throughout to add various fractals and such that will allow 
       me to explore different kinds of scenes (also Ambient Occlusion is coming at some point. I promise.) 

        </p>

  </div>

</body>
</html>
